{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "from tomato.audio.AudioAnalyzer import AudioAnalyzer\n",
    "from tomato.symbolic.SymbTrAnalyzer import SymbTrAnalyzer\n",
    "from tomato.joint.JointAnalyzer import JointAnalyzer\n",
    "import pylab\n",
    "pylab.rcParams['figure.figsize'] = (20, 8)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "JointAnalyzer assumes the individual audio analysis and score analysis is applied earlier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# score filepaths\n",
    "symbtr_name = 'ussak--sazsemaisi--aksaksemai----neyzen_aziz_dede'\n",
    "txt_score_filepath = os.path.join(symbtr_name, symbtr_name + '.txt')\n",
    "mu2_score_filepath = os.path.join(symbtr_name, symbtr_name + '.mu2')\n",
    "\n",
    "# instantiate\n",
    "audio_mbid = 'f970f1e0-0be9-4914-8302-709a0eac088e'\n",
    "audio_filepath = os.path.join(symbtr_name, audio_mbid, audio_mbid + '.mp3')\n",
    "\n",
    "# instantiate analyzer objects\n",
    "scoreAnalyzer = SymbTrAnalyzer(verbose=True)\n",
    "audioAnalyzer = AudioAnalyzer(verbose=True)\n",
    "jointAnalyzer = JointAnalyzer(verbose=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we compute the input score and audio features for joint analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Automatic phrase segmentation on the SymbTr-txt file: ussak--sazsemaisi--aksaksemai----neyzen_aziz_dede/ussak--sazsemaisi--aksaksemai----neyzen_aziz_dede.txt\n",
      "- Extracting (meta)data from the SymbTr-txt file: ussak--sazsemaisi--aksaksemai----neyzen_aziz_dede/ussak--sazsemaisi--aksaksemai----neyzen_aziz_dede.txt\n",
      "- Extracting metadata from the SymbTr-mu2 file: ussak--sazsemaisi--aksaksemai----neyzen_aziz_dede/ussak--sazsemaisi--aksaksemai----neyzen_aziz_dede.mu2\n",
      "- Extracting predominant melody of ussak--sazsemaisi--aksaksemai----neyzen_aziz_dede/f970f1e0-0be9-4914-8302-709a0eac088e/f970f1e0-0be9-4914-8302-709a0eac088e.mp3\n"
     ]
    }
   ],
   "source": [
    "# score (meta)data analysis\n",
    "score_data = scoreAnalyzer.analyze(txt_score_filepath, mu2_score_filepath)\n",
    "\n",
    "# predominant melody extraction\n",
    "audio_pitch = audioAnalyzer.extract_pitch(audio_filepath)\n",
    "\n",
    "# NOTE: do not call pitch filter later as aligned_pitch_filter will be more effective"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, you can use the single line call \"analyze,\" which does all the available analysis simultaneously. You can then update the audio analysis using the joint analysis results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Extracting score-informed tonic and tempo of ussak--sazsemaisi--aksaksemai----neyzen_aziz_dede/f970f1e0-0be9-4914-8302-709a0eac088e/f970f1e0-0be9-4914-8302-709a0eac088e.mp3\n",
      "- Aligning audio recording ussak--sazsemaisi--aksaksemai----neyzen_aziz_dede/f970f1e0-0be9-4914-8302-709a0eac088e/f970f1e0-0be9-4914-8302-709a0eac088e.mp3 and music score ussak--sazsemaisi--aksaksemai----neyzen_aziz_dede/ussak--sazsemaisi--aksaksemai----neyzen_aziz_dede.txt.\n",
      "- Filtering predominant melody of ussak--sazsemaisi--aksaksemai----neyzen_aziz_dede/f970f1e0-0be9-4914-8302-709a0eac088e/f970f1e0-0be9-4914-8302-709a0eac088e.mp3 after audio-score alignment.\n",
      "- Computing the note models for ussak--sazsemaisi--aksaksemai----neyzen_aziz_dede/f970f1e0-0be9-4914-8302-709a0eac088e/f970f1e0-0be9-4914-8302-709a0eac088e.mp3\n",
      "- Obtaining the melodic progression model of ussak--sazsemaisi--aksaksemai----neyzen_aziz_dede/f970f1e0-0be9-4914-8302-709a0eac088e/f970f1e0-0be9-4914-8302-709a0eac088e.mp3\n",
      "- Computing pitch distribution of ussak--sazsemaisi--aksaksemai----neyzen_aziz_dede/f970f1e0-0be9-4914-8302-709a0eac088e/f970f1e0-0be9-4914-8302-709a0eac088e.mp3\n",
      "- Identifying the transposition of ussak--sazsemaisi--aksaksemai----neyzen_aziz_dede/f970f1e0-0be9-4914-8302-709a0eac088e/f970f1e0-0be9-4914-8302-709a0eac088e.mp3\n"
     ]
    }
   ],
   "source": [
    "# joint analysis\n",
    "joint_features, score_informed_audio_features = jointAnalyzer.analyze(\n",
    "    txt_score_filepath, score_data, audio_filepath, audio_pitch)\n",
    "\n",
    "# redo some steps in audio analysis\n",
    "score_informed_audio_features = audioAnalyzer.update_analysis(score_informed_audio_features)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... or the individual calls are given  below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Automatic phrase segmentation on the SymbTr-txt file: ussak--sazsemaisi--aksaksemai----neyzen_aziz_dede/ussak--sazsemaisi--aksaksemai----neyzen_aziz_dede.txt\n"
     ]
    }
   ],
   "source": [
    "# score (meta)data analysis\n",
    "score_features = scoreAnalyzer.analyze(\n",
    "    txt_score_filepath, mu2_score_filepath, symbtr_name=symbtr_name)\n",
    "\n",
    "# predominant melody extraction\n",
    "pitch = audioAnalyzer.extract_pitch(audio_filepath)\n",
    "\n",
    "# joint analysis\n",
    "# score-informed tonic and tempo estimation\n",
    "tonic, tempo = jointAnalyzer.extract_tonic_tempo(\n",
    "    txt_score_filepath, score_data, audio_filepath, audio_pitch)\n",
    "\n",
    "# section linking and note-level alignment\n",
    "sections, notes, section_candidates = jointAnalyzer.align_audio_score(\n",
    "    txt_score_filepath, score_data, audio_filepath, audio_pitch, tonic, tempo)\n",
    "\n",
    "# aligned pitch filter\n",
    "pitch_filtered, notes_filtered = jointAnalyzer.filter_pitch(audio_pitch, notes)\n",
    "\n",
    "# aligned note model\n",
    "note_models, pitch_distribution, aligned_tonic = jointAnalyzer.get_note_models(\n",
    "    pitch_filtered, notes_filtered, tonic['symbol'])\n",
    "\n",
    "# recompute the audio features using the filtered pitch and tonic\n",
    "# pitch histograms\n",
    "pitch_class_distribution = pitch_distribution.to_pcd()\n",
    "\n",
    "# get the melodic progression model\n",
    "melodic_progression = audioAnalyzer.get_melodic_progression(pitch_filtered)\n",
    "\n",
    "# transposition (ahenk) identification\n",
    "transposition = audioAnalyzer.identify_transposition(aligned_tonic, aligned_tonic['symbol'])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
