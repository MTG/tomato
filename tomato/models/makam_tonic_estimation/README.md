# Precomputed training models for tonic identification and makam recognition

The model is computed using the [dlfm2016 makam recognition experiments](https://github.com/MTG/otmm_makam_recognition_dataset/releases/tag/dlfm2016) repository. Note that due to the size constraints the features are stored in Zenodo ([link](https://zenodo.org/record/57999#.V7yPD3V97CI)).

The training data is obtained from the [dlfm2016 release of otmm_makam_recognition_dataset](https://github.com/MTG/otmm_makam_recognition_dataset/tree/dlfm2016). We use best performing training parameter set of joint identification task (pitch-class distributions with 7.5 cent bin size and 15 cent kernel width).

Please refer to the paper below, if you are using this training model:

> Karakurt, A., Şentürk S., & Serra X. (2016). MORTY: A Toolbox for Mode Recognition and Tonic Identification. In Proceedings of 3rd International Digital Libraries for Musicology Workshop (DLfM 2016). pages 9-16, New York, NY, USA

The precomputed training models for tonic identification and makam recognition by __Sertan Şentürk__ is licensed under a Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License. To view a copy of this license, visit http://creativecommons.org/licenses/by/4.0/.
